{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# 2\n",
    "glove_file = datapath(\"C:\\chungnam_chatbot\\pytorch\\data2\\glove.6B.100d.txt\")\n",
    "word2vec_glove_file = get_tmpfile(\n",
    "    \"C:\\chungnam_chatbot\\pytorch\\data2\\glove.6B.100d.vector.txt\"\n",
    ")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23268\\2162345239.py:6: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
    "  glove2word2vec(glove_file, word2vec_glove_file)\n",
    "(400000, 100)\n",
    "# 3\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "model.most_similar(\"bill\")\n",
    "[('legislation', 0.8072139620780945),\n",
    " ('proposal', 0.730686366558075),\n",
    " ('senate', 0.7142541408538818),\n",
    " ('bills', 0.704440176486969),\n",
    " ('measure', 0.6958035230636597),\n",
    " ('passed', 0.6906245350837708),\n",
    " ('amendment', 0.6846878528594971),\n",
    " ('provision', 0.6845566630363464),\n",
    " ('plan', 0.6816462874412537),\n",
    " ('clinton', 0.6663140058517456)]\n",
    "model.most_similar(\"cherry\")\n",
    "[('peach', 0.688809871673584),\n",
    " ('mango', 0.6838189959526062),\n",
    " ('plum', 0.6684104204177856),\n",
    " ('berry', 0.6590359807014465),\n",
    " ('grove', 0.6581552028656006),\n",
    " ('blossom', 0.6503506302833557),\n",
    " ('raspberry', 0.6477391719818115),\n",
    " ('strawberry', 0.6442098021507263),\n",
    " ('pine', 0.6390928626060486),\n",
    " ('almond', 0.6379212737083435)]\n",
    "# 5\n",
    "result = model.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"])\n",
    "for re in result:\n",
    "    print(f\"{re[0]} {re[1]:.4f}\")\n",
    "queen 0.7699\n",
    "monarch 0.6843\n",
    "throne 0.6756\n",
    "daughter 0.6595\n",
    "princess 0.6521\n",
    "prince 0.6517\n",
    "elizabeth 0.6465\n",
    "mother 0.6312\n",
    "emperor 0.6106\n",
    "wife 0.6099\n",
    "# 6\n",
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]\n",
    "\n",
    "\n",
    "print(analogy(\"australia\", \"beer\", \"france\"))\n",
    "print(analogy(\"tail\", \"tallest\", \"long\"))\n",
    "\n",
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "champagne\n",
    "world\n",
    "cereal\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
